{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJcfvi1V3Why"
      },
      "source": [
        "from argparse import ArgumentParser\n",
        "import importlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "print(\"Start detecting body pose on one image\")\n",
        "\n",
        "#Argumente werden festgelegt, u.a. welches Model genutzt wird und welche Datenbank.\n",
        "def opts_parser():\n",
        "    usage = 'Configure the dataset using image from ./data'\n",
        "    parser = ArgumentParser(description=usage)\n",
        "    parser.add_argument(\n",
        "        '--model_class', type=str, default='selecsls', metavar='FILE',\n",
        "        help='Select model type to use (DenseNet, SelecSLS, ResNet etc.)')\n",
        "    parser.add_argument(\n",
        "        '--model_config', type=str, default='SelecSLS60', metavar='NET_CONFIG',\n",
        "        help='Select the model configuration')\n",
        "    parser.add_argument(\n",
        "        '--model_weights', type=str, default='./weights/SelecSLS60_statedict.pth', metavar='FILE',\n",
        "        help='Path to model weights')\n",
        "    parser.add_argument(\n",
        "        '--dataset_base_path', type=str, default='./data', metavar='FILE',\n",
        "        help='Path to ImageNet dataset')\n",
        "    parser.add_argument(\n",
        "        '--gpu_id', type=int, default=0,\n",
        "        help='Which GPU to use.')\n",
        "    parser.add_argument(\n",
        "        '--simulate_pruning', type=bool, default=False,\n",
        "        help='Whether to zero out features with gamma below a certain threshold')\n",
        "    parser.add_argument(\n",
        "        '--pruned_and_fused', type=bool, default=False,\n",
        "        help='Whether to prune based on gamma below a certain threshold and fuse BN')\n",
        "    parser.add_argument(\n",
        "        '--gamma_thresh', type=float, default=1e-4,\n",
        "        help='gamma threshold to use for simulating pruning')\n",
        "    return parser\n",
        "\n",
        "\n",
        "def start_recognizing_body_pose(model_class, model_config, model_weights, dataset_base_path, gpu_id, simulate_pruning, pruned_and_fused, gamma_thresh):\n",
        "    print(\"Starting to recognize body pose (detect_body_pose.py line 47)\")\n",
        "\n",
        "    model_module = importlib.import_module('models.'+model_class)\n",
        "    net = model_module.Net(nClasses=1000, config=model_config)\n",
        "    net.load_state_dict(torch.load(model_weights, map_location= lambda storage, loc: storage))\n",
        "\n",
        "    device = torch.device(\"cuda:\"+str(gpu_id) if torch.cuda.is_available() else \"cpu\")\n",
        "    net = net.to(device)\n",
        "    if pruned_and_fused:\n",
        "        print('Fusing BN and pruning channels based on gamma ' + str(gamma_thresh))\n",
        "        net.prune_and_fuse(gamma_thresh)\n",
        "\n",
        "    if simulate_pruning:\n",
        "        print('Simulating pruning by zeroing all features with gamma less than '+str(gamma_thresh))\n",
        "        with torch.no_grad():\n",
        "            for n, m in net.named_modules():\n",
        "                if isinstance(m, nn.BatchNorm2d):\n",
        "                    m.weight[abs(m.weight) < gamma_thresh] = 0\n",
        "                    m.bias[abs(m.weight) < gamma_thresh] = 0\n",
        "\n",
        "    # defines transformation of images (so every image has the same size etc) \n",
        "    # also images get transformed to PyTorch tensors\n",
        "    norm_transform = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        norm_transform\n",
        "    ])\n",
        "\n",
        "    print(f\"Loading local dataset (detect_body_pose.py line 77) in {dataset_base_path}\")\n",
        "    # loading dataset and transforming it\n",
        "    dataset = dset.ImageFolder(dataset_base_path, transform=transform)\n",
        "    test_loader = DataLoader(dataset, batch_size=1,\n",
        "                              shuffle=True, num_workers=0)\n",
        "\n",
        "    print(f\"The type of the loaded dataset is: {type(test_loader)}\")\n",
        "    print(f\"Shape of loaded dataset is: {np.shape(test_loader)}\")\n",
        "    #print(f\"The type of the img is: {type(img)}\")\n",
        "    #print(f\"Shape of img is: {np.shape(img)}\")\n",
        "    plt.imshow(test_loader, cmap='gray')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = opts_parser()\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    start_recognizing_body_pose(**vars(args))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}